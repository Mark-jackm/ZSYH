{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wkd = pd.read_csv('data/wkd_v1.csv')\n",
    "train = pd.read_csv('train_v2.csv')\n",
    "train = pd.merge(train, wkd, left_on='date', right_on='ORIG_DT', how='left')\n",
    "train['amount_hour_sum'] = train.groupby(['date', 'biz_type', 'periods'])['amount'].transform('sum')\n",
    "\n",
    "train['Day'] = train['date'].apply(lambda x: int(x.split('/')[-1]))\n",
    "train['d'] = train['date'].apply(lambda x: x[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biz_list = train['biz_type'].unique()\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def get_df_period(x):\n",
    "    k = train[train['biz_type'] == x]\n",
    "    k = k.drop_duplicates(['date', 'periods'])\n",
    "    k['shift_WKD'] = k['WKD_TYP_CD'].shift(48)\n",
    "    k['shift_WKD_'] = k['WKD_TYP_CD'].shift(-48)\n",
    "    k = k.fillna('-1')\n",
    "    k['WKD_+1'] = k['WKD_TYP_CD'] + k['shift_WKD']\n",
    "    k['WKD_-1'] = k['WKD_TYP_CD'] + k['shift_WKD_']\n",
    "    k['WKD_'] = k['shift_WKD'] + k['WKD_TYP_CD'] + k['shift_WKD_']\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 13/13 [00:01<00:00, 10.97it/s]\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for i in tqdm(biz_list[:-1]):\n",
    "    df.append(get_df_period(i))\n",
    "k = pd.concat(df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_v1_periods = pd.read_csv('test_v2_periods.csv')\n",
    "test_v1_periods = pd.merge(test_v1_periods, wkd, left_on='date', right_on='ORIG_DT', how='left')\n",
    "\n",
    "test_v1_periods_A = test_v1_periods[test_v1_periods['post_id'] == 'A']\n",
    "test_v1_periods_A['shift_WKD'] = test_v1_periods_A['WKD_TYP_CD'].shift(48)\n",
    "test_v1_periods_A['shift_WKD_'] = test_v1_periods_A['WKD_TYP_CD'].shift(-48)\n",
    "test_v1_periods_A['shift_WKD'] = test_v1_periods_A['shift_WKD'].fillna('SN')\n",
    "test_v1_periods_A['shift_WKD_'] = test_v1_periods_A['shift_WKD_'].fillna('SN')\n",
    "test_v1_periods_A['WKD_+1'] = test_v1_periods_A['WKD_TYP_CD'] + test_v1_periods_A['shift_WKD']\n",
    "test_v1_periods_A['WKD_-1'] = test_v1_periods_A['WKD_TYP_CD'] + test_v1_periods_A['shift_WKD_']\n",
    "test_v1_periods_A['WKD_'] = test_v1_periods_A['shift_WKD'] + test_v1_periods_A['WKD_TYP_CD'] + test_v1_periods_A['shift_WKD_']\n",
    "\n",
    "test_v1_periods_A['Day'] = test_v1_periods_A['date'].apply(lambda x: int(x.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                       | 1/13 [00:00<00:06,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -0.848714\tvalid_1's poisson: -0.309527\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's poisson: -0.778559\tvalid_1's poisson: -0.316356\n",
      "0.15038460158183703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▌                                    | 2/13 [00:00<00:05,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -2.52855\tvalid_1's poisson: -1.2853\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's poisson: -2.5229\tvalid_1's poisson: -1.29344\n",
      "0.24637955121176336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████▉                                 | 3/13 [00:01<00:04,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: 0.452102\tvalid_1's poisson: 0.449271\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's poisson: 0.453475\tvalid_1's poisson: 0.445186\n",
      "0.2094217977571942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████▏                             | 4/13 [00:01<00:04,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -23.3711\tvalid_1's poisson: -3.66495\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's poisson: -19.6662\tvalid_1's poisson: -5.76322\n",
      "0.18154919905402594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████▌                          | 5/13 [00:02<00:03,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -2.45944\tvalid_1's poisson: -0.464015\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's poisson: -2.1502\tvalid_1's poisson: -0.642784\n",
      "0.21509168191949896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|███████████████████▊                       | 6/13 [00:02<00:03,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -62.4593\tvalid_1's poisson: -49.9387\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's poisson: -62.1825\tvalid_1's poisson: -50.0931\n",
      "0.12887821575107483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████▏                   | 7/13 [00:03<00:02,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: 0.2475\tvalid_1's poisson: 0.095941\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's poisson: 0.2475\tvalid_1's poisson: 0.095941\n",
      "0.0020833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████▍                | 8/13 [00:03<00:02,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -302.241\tvalid_1's poisson: -300.065\n",
      "[100]\ttraining's poisson: -302.257\tvalid_1's poisson: -300.055\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's poisson: -302.241\tvalid_1's poisson: -300.065\n",
      "0.06297867904574153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|█████████████████████████████▊             | 9/13 [00:03<00:01,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -5.07593\tvalid_1's poisson: -1.4297\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's poisson: -4.52991\tvalid_1's poisson: -1.71166\n",
      "0.18101233153567323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|████████████████████████████████▎         | 10/13 [00:04<00:01,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -25.8912\tvalid_1's poisson: -14.4512\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's poisson: -25.2041\tvalid_1's poisson: -14.8305\n",
      "0.13682025746834536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████▌      | 11/13 [00:04<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -4.32783\tvalid_1's poisson: -1.61597\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's poisson: -4.05061\tvalid_1's poisson: -1.82651\n",
      "0.17006622332394358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|██████████████████████████████████████▊   | 12/13 [00:05<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -1119.11\tvalid_1's poisson: -984.778\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's poisson: -1117.63\tvalid_1's poisson: -985.665\n",
      "0.0846546612221229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 13/13 [00:05<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -129.614\tvalid_1's poisson: -61.027\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's poisson: -125.465\tvalid_1's poisson: -63.7105\n",
      "0.16573573054729093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 分细岗位单独训练\n",
    "df_test = []\n",
    "mape_list = []\n",
    "for i in tqdm(biz_list[:-1]):\n",
    "    train1 = k[k['d'] != '2020/11'][k['biz_type'] == i]\n",
    "    train1_y = train1['amount_hour_sum']\n",
    "    \n",
    "    valid1 = k[k['biz_type'] == i]\n",
    "    valid1 = valid1[valid1['d'] == '2020/11']\n",
    "    valid1_y = valid1['amount_hour_sum']   \n",
    "    \n",
    "    test_v1_periods_A['biz_type'] = i\n",
    "    test = test_v1_periods_A.copy()\n",
    "    features = ['WKD_TYP_CD', 'shift_WKD', 'periods', 'Day']\n",
    "    cat_cols = ['WKD_TYP_CD', 'shift_WKD', 'periods',]\n",
    "\n",
    "    train1[cat_cols] = train1[cat_cols].astype('category')\n",
    "    valid1[cat_cols] = valid1[cat_cols].astype('category')\n",
    "    test[cat_cols] = test[cat_cols].astype('category')\n",
    "\n",
    "    params = {'learning_rate': 0.1, \n",
    "            'boosting_type': 'gbdt', \n",
    "            'objective': 'regression_l1',\n",
    "            'metric': 'poisson',\n",
    "            'n_jobs': -1, \n",
    "            'seed': 2019, \n",
    "            'verbosity': -1, \n",
    "           }\n",
    "\n",
    "\n",
    "    train_set = lgb.Dataset(train1[features], train1_y)\n",
    "    val_set = lgb.Dataset(valid1[features], valid1_y)\n",
    "\n",
    "    model = lgb.train(params, train_set, num_boost_round=5000,\n",
    "                      valid_sets=(train_set, val_set), early_stopping_rounds=50,\n",
    "                      verbose_eval=50,\n",
    "                     categorical_feature=cat_cols\n",
    "                     )\n",
    "    oof_train = model.predict(valid1[features])\n",
    "    test_predict = model.predict(test[features])\n",
    "    test['amount'] = test_predict\n",
    "    df_test.append(test)\n",
    "    mape_list.append((abs(valid1_y - oof_train) / (valid1_y + 1)).mean())\n",
    "    print((abs(valid1_y - oof_train) / (valid1_y + 1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14885048182706503"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mape_list) / len(mape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_v1_periods_A = test_v1_periods[test_v1_periods['post_id'] == 'B']\n",
    "test_v1_periods_A['shift_WKD'] = test_v1_periods_A['WKD_TYP_CD'].shift(48)\n",
    "test_v1_periods_A['shift_WKD_'] = test_v1_periods_A['WKD_TYP_CD'].shift(-48)\n",
    "test_v1_periods_A['shift_WKD'] = test_v1_periods_A['shift_WKD'].fillna('SN')\n",
    "test_v1_periods_A['shift_WKD_'] = test_v1_periods_A['shift_WKD_'].fillna('SN')\n",
    "test_v1_periods_A['WKD_+1'] = test_v1_periods_A['WKD_TYP_CD'] + test_v1_periods_A['shift_WKD']\n",
    "test_v1_periods_A['WKD_-1'] = test_v1_periods_A['WKD_TYP_CD'] + test_v1_periods_A['shift_WKD_']\n",
    "test_v1_periods_A['WKD_'] = test_v1_periods_A['shift_WKD'] + test_v1_periods_A['WKD_TYP_CD'] + test_v1_periods_A['shift_WKD_']\n",
    "\n",
    "test_v1_periods_A['Day'] = test_v1_periods_A['date'].apply(lambda x: int(x.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's poisson: -253.7\tvalid_1's poisson: -176.838\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's poisson: -251.545\tvalid_1's poisson: -177.925\n",
      "0.32619993613737847\n"
     ]
    }
   ],
   "source": [
    "i = 'B1'\n",
    "k = get_df_period(i)\n",
    "train1 = k[k['d'] != '2020/11'][k['biz_type'] == i]\n",
    "train1_y = train1['amount_hour_sum']\n",
    "\n",
    "valid1 = k[k['biz_type'] == i]\n",
    "valid1 = valid1[valid1['d'] == '2020/11']\n",
    "valid1_y = valid1['amount_hour_sum']   \n",
    "\n",
    "\n",
    "test = test_v1_periods_A.copy()\n",
    "\n",
    "features = ['WKD_TYP_CD', 'shift_WKD', 'periods', 'Day']\n",
    "cat_cols = ['WKD_TYP_CD', 'shift_WKD', 'periods',]\n",
    "\n",
    "train1[cat_cols] = train1[cat_cols].astype('category')\n",
    "valid1[cat_cols] = valid1[cat_cols].astype('category')\n",
    "test[cat_cols] = test[cat_cols].astype('category')\n",
    "\n",
    "params = {'learning_rate': 0.1, \n",
    "        'boosting_type': 'gbdt', \n",
    "        'objective': 'regression_l1',\n",
    "        'metric': 'poisson',\n",
    "        'n_jobs': -1, \n",
    "        'seed': 2019, \n",
    "        'verbosity': -1, \n",
    "       }\n",
    "\n",
    "\n",
    "train_set = lgb.Dataset(train1[features], train1_y)\n",
    "val_set = lgb.Dataset(valid1[features], valid1_y)\n",
    "\n",
    "model = lgb.train(params, train_set, num_boost_round=5000,\n",
    "                  valid_sets=(train_set, val_set), early_stopping_rounds=50,\n",
    "                  verbose_eval=50,\n",
    "                 categorical_feature=cat_cols\n",
    "                 )\n",
    "oof_train = model.predict(valid1[features])\n",
    "test_predict = model.predict(test[features])\n",
    "test['amount'] = test_predict\n",
    "df_test.append(test)\n",
    "print((abs(valid1_y - oof_train) / (valid1_y + 1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564845.7662743723"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.concat(df_test, axis=0)\n",
    "sum(d.amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564288"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d.groupby(['date', 'post_id', 'periods'])['amount'].sum().reset_index()\n",
    "d = pd.merge(test_v1_periods[['date', 'post_id', 'periods']], d, on=['date', 'post_id', 'periods'], how='left')\n",
    "d['amount'] = d['amount'].astype('int')\n",
    "d.to_csv('sub_periods_lgb_hour.txt', index=False)\n",
    "sum(d.amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale\n",
    "test_ = d.copy()\n",
    "test_['date'] = pd.to_datetime(test_['date'])\n",
    "data_day = pd.read_csv('sub_day_lgb_all_666.txt')\n",
    "data_day['date'] = pd.to_datetime(data_day['date'])\n",
    "test_['day_sum'] = test_.groupby(['date', 'post_id'])['amount'].transform('sum')\n",
    "test_ = pd.merge(test_, data_day, on=['date', 'post_id'], how='left')\n",
    "test_['ratio'] = test_['day_sum'] / test_['amount_y']\n",
    "test_['amount'] = test_['amount_x'] / test_['ratio']\n",
    "test_['amount'] = test_['amount'].fillna(0)\n",
    "test_['amount'] = test_['amount'].astype('int')\n",
    "test_[['date', 'post_id', 'periods', 'amount' ]].to_csv('sub_periods_scale_lgb.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587328"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_['amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensemble\n",
    "arima = pd.read_csv('sub_periods_scale_arima.txt')\n",
    "test_['amount'] = (test_['amount'] + arima['amount']) // 2\n",
    "test_[['date', 'post_id', 'periods', 'amount' ]].to_csv('sub_periods_scale_combine.txt', index=False)\n",
    "test_['amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
